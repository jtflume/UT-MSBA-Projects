{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad0cfcc",
   "metadata": {},
   "source": [
    "# LDA Topic Model \n",
    "\n",
    "This code is pulled from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/. \n",
    "\n",
    "We apply an LDA Topic Model to reviews of companies on Glassdoor to understand what topics/categories people talk about when describing their work place / work experience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f6abf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e77433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc21cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/connorgilmore/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9866fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from .mio5_utils import VarReader5\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/connorgilmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c743b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d126dd",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac6a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9dca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Hours, pay, management and environment</td>\n",
       "      <td>I wouldn’t say I had any cons working at this job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Work your very own schedule</td>\n",
       "      <td>Sometimes the pay can be unbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Uber stock, good benefits, good experience</td>\n",
       "      <td>Bad commission structure, limited upside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Decent pay for the work you do.</td>\n",
       "      <td>The customer service department doesnt take th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Smart people\\r\\nLots of resources\\r\\nGreat com...</td>\n",
       "      <td>Fast-moving org - sometimes a little too fast ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 company                                               pros  \\\n",
       "0           0    Uber             Hours, pay, management and environment   \n",
       "1           1    Uber                        Work your very own schedule   \n",
       "2           2    Uber         Uber stock, good benefits, good experience   \n",
       "3           3    Uber                    Decent pay for the work you do.   \n",
       "4           4    Uber  Smart people\\r\\nLots of resources\\r\\nGreat com...   \n",
       "\n",
       "                                                cons  \n",
       "0  I wouldn’t say I had any cons working at this job  \n",
       "1                Sometimes the pay can be unbalanced  \n",
       "2           Bad commission structure, limited upside  \n",
       "3  The customer service department doesnt take th...  \n",
       "4  Fast-moving org - sometimes a little too fast ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a182495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['combined'] = reviews_df['pros'] + reviews_df['cons']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0813b2",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf45c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reviews_df['pros']\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64dedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d8ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba5cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77448d64",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fe645e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edec9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        #model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model = lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8da2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=5, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6307d",
   "metadata": {},
   "source": [
    "## Visualize Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=10; start=5; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0970a8",
   "metadata": {},
   "source": [
    "Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = model_list[1]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e952a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.111*\"work\" + 0.067*\"life\" + 0.065*\"balance\" + 0.044*\"good\" + '\n",
      "  '0.025*\"company\" + 0.021*\"great\" + 0.019*\"people\" + 0.017*\"culture\" + '\n",
      "  '0.015*\"benefit\" + 0.013*\"environment\" + 0.011*\"opportunity\" + '\n",
      "  '0.011*\"employee\" + 0.010*\"flexible\" + 0.009*\"excellent\" + 0.009*\"hour\" + '\n",
      "  '0.008*\"really\" + 0.008*\"lot\" + 0.008*\"focus\" + 0.007*\"team\" + '\n",
      "  '0.007*\"leadership\" + 0.006*\"care\" + 0.006*\"well\" + 0.006*\"make\" + '\n",
      "  '0.006*\"pay\" + 0.005*\"time\" + 0.005*\"nice\" + 0.005*\"flexibility\" + '\n",
      "  '0.005*\"schedule\" + 0.005*\"management\" + 0.004*\"amazing\"'),\n",
      " (1,\n",
      "  '0.104*\"good\" + 0.036*\"work\" + 0.025*\"people\" + 0.023*\"great\" + 0.022*\"pay\" '\n",
      "  '+ 0.021*\"benefit\" + 0.020*\"nice\" + 0.017*\"salary\" + 0.014*\"bonus\" + '\n",
      "  '0.013*\"manager\" + 0.013*\"project\" + 0.012*\"culture\" + 0.012*\"learn\" + '\n",
      "  '0.011*\"job\" + 0.010*\"company\" + 0.008*\"pretty\" + 0.008*\"amazing\" + '\n",
      "  '0.007*\"change\" + 0.007*\"colleague\" + 0.006*\"willing\" + 0.006*\"always\" + '\n",
      "  '0.006*\"development\" + 0.006*\"smart\" + 0.006*\"lot\" + 0.006*\"training\" + '\n",
      "  '0.005*\"life\" + 0.005*\"product\" + 0.005*\"first\" + 0.005*\"really\" + '\n",
      "  '0.005*\"industry\"'),\n",
      " (2,\n",
      "  '0.069*\"great\" + 0.037*\"work\" + 0.034*\"opportunity\" + 0.033*\"company\" + '\n",
      "  '0.027*\"lot\" + 0.024*\"benefit\" + 0.022*\"people\" + 0.017*\"learn\" + '\n",
      "  '0.016*\"growth\" + 0.015*\"culture\" + 0.013*\"team\" + 0.011*\"grow\" + '\n",
      "  '0.010*\"good\" + 0.010*\"experience\" + 0.007*\"many\" + 0.007*\"career\" + '\n",
      "  '0.007*\"role\" + 0.007*\"job\" + 0.006*\"room\" + 0.006*\"different\" + '\n",
      "  '0.006*\"environment\" + 0.006*\"exposure\" + 0.006*\"challenge\" + 0.006*\"day\" + '\n",
      "  '0.005*\"year\" + 0.005*\"time\" + 0.005*\"smart\" + 0.005*\"leadership\" + '\n",
      "  '0.005*\"start\" + 0.005*\"part\"'),\n",
      " (3,\n",
      "  '0.104*\"work\" + 0.054*\"good\" + 0.033*\"great\" + 0.026*\"benefit\" + '\n",
      "  '0.025*\"place\" + 0.018*\"employee\" + 0.017*\"environment\" + 0.017*\"flexible\" + '\n",
      "  '0.016*\"company\" + 0.013*\"people\" + 0.013*\"time\" + 0.010*\"team\" + '\n",
      "  '0.010*\"schedule\" + 0.008*\"friendly\" + 0.008*\"really\" + 0.008*\"management\" + '\n",
      "  '0.007*\"culture\" + 0.007*\"pay\" + 0.006*\"home\" + 0.006*\"want\" + 0.006*\"life\" '\n",
      "  '+ 0.006*\"balance\" + 0.005*\"care\" + 0.005*\"always\" + 0.005*\"get\" + '\n",
      "  '0.005*\"amazing\" + 0.005*\"career\" + 0.005*\"hour\" + 0.005*\"love\" + '\n",
      "  '0.005*\"opportunity\"'),\n",
      " (4,\n",
      "  '0.040*\"great\" + 0.025*\"team\" + 0.020*\"opportunity\" + 0.019*\"employee\" + '\n",
      "  '0.017*\"company\" + 0.016*\"work\" + 0.012*\"good\" + 0.012*\"job\" + 0.011*\"lot\" + '\n",
      "  '0.010*\"many\" + 0.010*\"leadership\" + 0.009*\"benefit\" + 0.009*\"experience\" + '\n",
      "  '0.008*\"time\" + 0.008*\"strong\" + 0.008*\"value\" + 0.007*\"helpful\" + '\n",
      "  '0.007*\"culture\" + 0.007*\"pay\" + 0.007*\"interest\" + 0.006*\"learning\" + '\n",
      "  '0.006*\"career\" + 0.006*\"growth\" + 0.006*\"allow\" + 0.005*\"care\" + '\n",
      "  '0.005*\"way\" + 0.005*\"really\" + 0.005*\"make\" + 0.005*\"amp\" + 0.005*\"help\"'),\n",
      " (5,\n",
      "  '0.054*\"good\" + 0.040*\"benefit\" + 0.029*\"flexible\" + 0.026*\"schedule\" + '\n",
      "  '0.023*\"pay\" + 0.021*\"great\" + 0.018*\"opportunity\" + 0.016*\"project\" + '\n",
      "  '0.015*\"growth\" + 0.014*\"career\" + 0.013*\"work\" + 0.012*\"job\" + 0.011*\"hour\" '\n",
      "  '+ 0.010*\"client\" + 0.009*\"lot\" + 0.009*\"many\" + 0.009*\"salary\" + '\n",
      "  '0.008*\"office\" + 0.008*\"training\" + 0.008*\"easy\" + 0.008*\"different\" + '\n",
      "  '0.007*\"system\" + 0.007*\"flexibility\" + 0.007*\"employee\" + '\n",
      "  '0.007*\"technology\" + 0.007*\"help\" + 0.006*\"learn\" + 0.006*\"boss\" + '\n",
      "  '0.006*\"security\" + 0.005*\"keep\"'),\n",
      " (6,\n",
      "  '0.077*\"good\" + 0.045*\"pay\" + 0.033*\"benefit\" + 0.031*\"work\" + '\n",
      "  '0.023*\"company\" + 0.020*\"decent\" + 0.017*\"people\" + 0.015*\"great\" + '\n",
      "  '0.015*\"culture\" + 0.014*\"lot\" + 0.012*\"time\" + 0.012*\"team\" + 0.011*\"money\" '\n",
      "  '+ 0.010*\"employee\" + 0.009*\"hour\" + 0.009*\"balance\" + 0.009*\"salary\" + '\n",
      "  '0.009*\"life\" + 0.008*\"opportunity\" + 0.006*\"high\" + 0.006*\"make\" + '\n",
      "  '0.006*\"learn\" + 0.006*\"interesting\" + 0.006*\"amazing\" + 0.005*\"competitive\" '\n",
      "  '+ 0.005*\"easy\" + 0.005*\"client\" + 0.005*\"really\" + 0.005*\"project\" + '\n",
      "  '0.005*\"overall\"'),\n",
      " (7,\n",
      "  '0.054*\"people\" + 0.039*\"work\" + 0.038*\"great\" + 0.019*\"opportunity\" + '\n",
      "  '0.017*\"good\" + 0.017*\"nice\" + 0.015*\"culture\" + 0.015*\"company\" + '\n",
      "  '0.013*\"team\" + 0.010*\"different\" + 0.010*\"benefit\" + 0.009*\"employee\" + '\n",
      "  '0.009*\"learn\" + 0.008*\"care\" + 0.007*\"provide\" + 0.007*\"skill\" + '\n",
      "  '0.007*\"job\" + 0.006*\"development\" + 0.006*\"growth\" + 0.006*\"take\" + '\n",
      "  '0.006*\"support\" + 0.006*\"group\" + 0.006*\"lot\" + 0.006*\"smart\" + '\n",
      "  '0.005*\"amazing\" + 0.005*\"make\" + 0.005*\"challenge\" + 0.005*\"really\" + '\n",
      "  '0.005*\"flexibility\" + 0.005*\"pay\"'),\n",
      " (8,\n",
      "  '0.041*\"benefit\" + 0.031*\"culture\" + 0.027*\"work\" + 0.027*\"care\" + '\n",
      "  '0.026*\"company\" + 0.021*\"great\" + 0.021*\"employee\" + 0.017*\"people\" + '\n",
      "  '0.012*\"well\" + 0.011*\"pay\" + 0.011*\"good\" + 0.009*\"flexibility\" + '\n",
      "  '0.009*\"amazing\" + 0.009*\"match\" + 0.008*\"pto\" + 0.008*\"take\" + '\n",
      "  '0.008*\"project\" + 0.007*\"value\" + 0.007*\"excellent\" + 0.007*\"time\" + '\n",
      "  '0.007*\"nice\" + 0.006*\"hour\" + 0.006*\"team\" + 0.006*\"day\" + 0.006*\"choose\" + '\n",
      "  '0.006*\"salary\" + 0.006*\"really\" + 0.006*\"manager\" + 0.005*\"average\" + '\n",
      "  '0.005*\"life\"'),\n",
      " (9,\n",
      "  '0.161*\"great\" + 0.049*\"work\" + 0.046*\"benefit\" + 0.026*\"company\" + '\n",
      "  '0.025*\"pay\" + 0.021*\"environment\" + 0.016*\"culture\" + 0.014*\"people\" + '\n",
      "  '0.013*\"employee\" + 0.013*\"leadership\" + 0.013*\"place\" + 0.012*\"growth\" + '\n",
      "  '0.012*\"balance\" + 0.011*\"team\" + 0.011*\"life\" + 0.010*\"management\" + '\n",
      "  '0.010*\"opportunity\" + 0.008*\"lot\" + 0.008*\"good\" + 0.008*\"amazing\" + '\n",
      "  '0.007*\"career\" + 0.007*\"decent\" + 0.007*\"care\" + 0.006*\"start\" + '\n",
      "  '0.006*\"job\" + 0.006*\"fun\" + 0.005*\"product\" + 0.005*\"learn\" + '\n",
      "  '0.005*\"available\" + 0.004*\"diversity\"')]\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=10)\n",
    "model_topics = lda_model.show_topics(formatted=False)\n",
    "pprint(lda_model.print_topics(num_words=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63595da5",
   "metadata": {},
   "source": [
    "## Visualize Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(optimal_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e5d7d",
   "metadata": {},
   "source": [
    "## Get Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c830002",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel.get_document_topics(bagOfWordOfADocument, minimum_probability=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
